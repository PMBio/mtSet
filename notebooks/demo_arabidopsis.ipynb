{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo illustrates how mtSet can be used for multi and single-trait set tests\n",
    "We consider a dataset of 192 samples and 3 flowering time phenotypes in A.thaliana from Atwell et al 2010 (Nature)\n",
    "Phenotypes were quantile-normalized to a gaussian distribution beforehand\n",
    "\n",
    "Here we consider 3 different models\n",
    "- mtSet: multi-trait analysis where relatedness is accounted for as a random effect\n",
    "- stSet: single-trait analysis where relatedness is accounted for as a random effect\n",
    "- mtSet1VC: multi-trait analysis where relatedness is account for with the first 5 principal components of the kinship as fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import sys\n",
    "import limix\n",
    "sys.path.append('./..')\n",
    "\n",
    "import mtSet.pycore.modules.splitter as SPLIT\n",
    "import mtSet.pycore.modules.multiTraitSetTest as MTST\n",
    "import mtSet.pycore.modules.chi2mixture as C2M\n",
    "from mtSet.pycore.utils.utils import smartAppend\n",
    "from mtSet.pycore.utils.utils import smartDumpDictHdf5\n",
    "\n",
    "import scipy as SP\n",
    "import h5py\n",
    "import pylab as PL\n",
    "import copy\n",
    "import os\n",
    "import cPickle\n",
    "import time as TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = {}\n",
    "files['data_dir'] = 'data'\n",
    "files['data'] = 'data/arab107_preprocessed.hdf5'\n",
    "files['data_url'] = 'http://www.ebi.ac.uk/~casale/arab107_preprocessed.hdf5'\n",
    "files['out_file'] = 'data/results.hdf5'\n",
    "files['split_cache'] = 'windows_split.hdf5'\n",
    "files['mtSet_null_cache'] = 'mtSet_null_cache.hdf5'\n",
    "files['stSet_null_cache'] = 'stSet_null_cache.hdf5'\n",
    "files['mtSet1VC_null_cache'] = 'mtSet1VC_null_cache.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data file if not there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b4965eda18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"file not found, downloading from %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtestfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['data']):\n",
    "    if not os.path.exists(files['data_dir']):\n",
    "        os.makedirs(files['data_dir'])\n",
    "    print \"file not found, downloading from %s\" % files['data_url']\n",
    "    testfile=urllib.URLopener()\n",
    "    testfile.retrieve(files['data_url'],files['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings for splitting the genome in different regions and permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "settings = {}\n",
    "settings['window_size']    = 1e4\n",
    "settings['minNumberSnps']  = 4\n",
    "settings['n_windows']      = 10\n",
    "settings['n_permutations'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = number of samples\n",
    "P = number of phenotypes\n",
    "V = number of variants\n",
    "K = number of covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f  = h5py.File(files['data'],'r')\n",
    "phenotype   = f['phenotype'][:]   # phenotype matrix (NxP)\n",
    "phenotypeID = f['phenotypeID'][:] # phenotype ids (P-vector)\n",
    "genotype    = f['genotype']       # genotype matrix (NxV)\n",
    "relatedness = f['relatedness'][:] # relatedness matrix (NxN)\n",
    "geno_pos    = f['geno_pos'][:]    # genotype positions (V-vector)\n",
    "geno_chrom  = f['geno_chrom'][:]  # genotype choromosomes (V-vector)\n",
    "covariates  = f['covariates'][:]  # covariate matrix (NxK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis with mtSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider no covariates for mtSet and stSet while we consider 6 covariates for mtSet1VC\n",
    "(intercept term and first 5 pcs of the relatedness matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi trait set test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtSet    = MTST.MultiTraitSetTest(phenotype,relatedness)\n",
    "mtSet1VC = MTST.MultiTraitSetTest(phenotype,F=covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit null models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtSet_null_info   = mtSet.fitNull(cache=True,fname=files['mtSet_null_cache'],rewrite=True)\n",
    "stSet_null_info   = mtSet.fitNullTraitByTrait(cache=True,fname=files['stSet_null_cache'],rewrite=True)\n",
    "mtSet1VC_null_info = mtSet1VC.fitNull(cache=True,fname=files['mtSet1VC_null_cache'],rewrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precompute genotype windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = SPLIT.Splitter(pos=geno_pos,chrom=geno_chrom)\n",
    "split.splitGeno(size=settings['window_size'],minSnps=settings['minNumberSnps'],cache=True,fname=files['split_cache'])\n",
    "nWindows = split.get_nWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set test scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n"
     ]
    }
   ],
   "source": [
    "RV = {}\n",
    "for window_idx in range(settings['n_windows']):\n",
    "\n",
    "    print '\\t.. window %d'%window_idx\n",
    "\n",
    "    # consider genetic region\n",
    "    Iregion, rv_windows = split.getWindow(window_idx)\n",
    "    region = genotype[:,Iregion]\n",
    "\n",
    "    # fit models\n",
    "    rv_mtSet = mtSet.optimize(region)\n",
    "    rv_stSet = mtSet.optimizeTraitByTrait(region)\n",
    "    rv_mtSet1VC = mtSet1VC.optimize(region)\n",
    "\n",
    "    # store LLR (log likelihood ratios) and window positions\n",
    "    smartAppend(RV,'window_chromosome',rv_windows['chrom'][0])\n",
    "    smartAppend(RV,'window_start',rv_windows['start'][0])\n",
    "    smartAppend(RV,'window_end',rv_windows['end'][0])\n",
    "    smartAppend(RV,'llr_mtSet',rv_mtSet1VC['LLR'][0])\n",
    "    smartAppend(RV,'llr_stSet',SP.concatenate([rv_stSet[key]['LLR'] for key in rv_stSet.keys()]))\n",
    "    smartAppend(RV,'llr_mtSet1VC',rv_mtSet1VC['LLR'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. permutation 0\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 1\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 2\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 3\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 4\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 5\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 6\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 7\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 8\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n",
      ".. permutation 9\n",
      "\t.. window 0\n",
      "\t.. window 1\n",
      "\t.. window 2\n",
      "\t.. window 3\n",
      "\t.. window 4\n",
      "\t.. window 5\n",
      "\t.. window 6\n",
      "\t.. window 7\n",
      "\t.. window 8\n",
      "\t.. window 9\n"
     ]
    }
   ],
   "source": [
    "for permutation_i in range(settings['n_permutations']):\n",
    "    print '.. permutation %d' % permutation_i\n",
    "\n",
    "    # set seed and generate sample permutation\n",
    "    SP.random.seed(permutation_i)\n",
    "    permutation = SP.random.permutation(phenotype.shape[0])\n",
    "\n",
    "    for window_idx in range(settings['n_windows']):\n",
    "\n",
    "        print '\\t.. window %d'%window_idx\n",
    "\n",
    "        # consider genetic region and permute\n",
    "        Iregion, rv_windows = split.getWindow(window_idx)\n",
    "        region = genotype[:,Iregion]\n",
    "        permuted_region = region[permutation,:]\n",
    "\n",
    "        # fit models\n",
    "        rv_mtSet = mtSet.optimize(permuted_region)\n",
    "        rv_stSet = mtSet.optimizeTraitByTrait(permuted_region)\n",
    "        rv_mtSet1VC = mtSet1VC.optimize(permuted_region)\n",
    "\n",
    "        # store permutation LLRs\n",
    "        smartAppend(RV,'permutation_llr_mtSet',rv_mtSet1VC['LLR'][0])\n",
    "        smartAppend(RV,'permutation_llr_stSet',SP.concatenate([rv_stSet[key]['LLR'] for key in rv_stSet.keys()]))\n",
    "        smartAppend(RV,'permutation_llr_mtSet1VC',rv_mtSet1VC['LLR'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize outputs\n",
    "for key in RV.keys():   RV[key] = SP.array(RV[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accurate estimation of pvalues either the number of windows or the number of permutations should be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "c2m = C2M.Chi2mixture(tol=4e-3)\n",
    "\n",
    "# obtain p-values for mtSet\n",
    "c2m.estimate_chi2mixture(RV['permutation_llr_mtSet'])\n",
    "RV['pv_mtSet'] = c2m.sf(RV['llr_mtSet'])\n",
    "RV['permutation_pv_mtSet'] = c2m.sf(RV['permutation_llr_mtSet'])\n",
    "\n",
    "# obtain p-values for stSet\n",
    "RV['pv_stSet'] = SP.zeros_like(RV['llr_stSet'])\n",
    "RV['permutation_pv_stSet'] = SP.zeros_like(RV['permutation_llr_stSet'])\n",
    "for p in range(phenotype.shape[1]):\n",
    "    c2m.estimate_chi2mixture(RV['permutation_llr_stSet'][:,p])\n",
    "    RV['pv_stSet'][:,p] = c2m.sf(RV['llr_stSet'][:,p])\n",
    "    RV['permutation_pv_stSet'][:,p] = c2m.sf(RV['permutation_llr_stSet'][:,p])\n",
    "\n",
    "# obtain p-values for mtSet1VC\n",
    "c2m.estimate_chi2mixture(RV['permutation_llr_mtSet1VC'])\n",
    "RV['pv_mtSet1VC'] = c2m.sf(RV['llr_mtSet1VC'])\n",
    "RV['permutation_pv_mtSet1VC'] = c2m.sf(RV['permutation_llr_mtSet1VC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fout = h5py.File(files['out_file'],'w')\n",
    "smartDumpDictHdf5(RV,fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
